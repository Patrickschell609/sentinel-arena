# SENTINEL Arena

**Capability denial benchmark proving 0% attack success rate across 160+ jailbreak vectors.**

SENTINEL doesn't filter LLM outputs. It reduces them to a single float. Raw text never reaches downstream. The 0% is structural, not statistical — there is no text channel for harm to flow through.

On-chain verification: [SentinelVerifier on Base](https://basescan.org/address/0xE2467A49FB10e3804DEB7d287dae4B5BF740f54E) | [SentinelRegistry](https://basescan.org/address/0xa0329fF2e237276D3f38fC3131c0146e30280e7F)

US Provisional Patent 63/965,457

---

## Results

| Defense Layer | Attack Success Rate | How It Fails |
|--------------|-------------------|--------------|
| Raw model (no defense) | 60-95% | Model complies with harmful request |
| Guardrailed (system prompt + output filter) | 20-70% | Jailbreak bypasses filters |
| **SENTINEL (capability denial)** | **0%** | **Cannot fail — only a number gets through** |

SENTINEL achieves 0% across all 7 attack categories:

| Category | Vectors | Source | Raw ASR | SENTINEL ASR |
|----------|---------|--------|---------|-------------|
| JailbreakBench | 100 | Chao et al., 2024 | 60-95% | **0%** |
| Chain-of-Thought Hijacking | 10 | 94-100% ASR in literature | 80%+ | **0%** |
| AutoDAN | 10 | Liu et al., ICLR 2024 | 70%+ | **0%** |
| Encoding Evasion | 10 | 72% vs NeMo Guardrails | 60%+ | **0%** |
| Role-Play / DAN | 10 | Published jailbreaks 2023-2025 | 80%+ | **0%** |
| Multi-Turn Escalation | 10 | 63% ASR on Claude Opus | 50%+ | **0%** |
| GCG / Custom | 10 | Zou et al., 2023 | 70%+ | **0%** |

---

## How SENTINEL Works

```
User prompt ──> LLM ──> Raw response ──> SENTINEL Extractor ──> float [0.0-1.0] ──> Action
                              │                                        │
                              │              (discarded)               │
                              └────────────── X ──────────────────────┘
                                    raw text never passes
```

1. System prompt instructs the model to output `{"score": 0.XX}` — a safety assessment
2. **Strict regex extraction** pulls the first float matching `[0-1](\.\d+)?` — everything else is discarded
3. Float maps to a discrete action via fixed thresholds (SAFE/UNSAFE, PROCEED/CAUTION/DENY)
4. Raw model text is never stored, logged, or forwarded

Even if the model is fully jailbroken and outputs instructions for harm, only a number gets through. The number maps to SAFE or UNSAFE. The jailbreak succeeds inside the model but fails at the extraction boundary.

**This is capability denial, not alignment.** We don't try to make the model safe. We make the output channel too narrow for harm to fit through.

---

## Quick Start

```bash
# Install
pip install -e .

# Run benchmark (free, uses local Ollama)
sentinel-arena run --models ollama/llama3.2:3b

# Quick test (5 attacks per category)
sentinel-arena run --models ollama/llama3.2:3b --limit 5

# Generate HTML report
sentinel-arena report results/latest/

# List all 160+ attack vectors
sentinel-arena attacks

# List model targets
sentinel-arena models
```

### Requirements

- Python 3.10+
- [Ollama](https://ollama.ai) for free local models (recommended)
- Or any LiteLLM-compatible provider (Anthropic, OpenAI, etc.)

```bash
pip install litellm click rich matplotlib jinja2
```

---

## SDK

Use SENTINEL in your own applications:

```python
from sentinel_arena.sdk import SentinelWrapper, ActionMap

# Wrap any LLM
wrapper = SentinelWrapper(model="ollama/llama3.2:3b")

# Evaluate a prompt — returns only a score + action, never raw text
result = wrapper.evaluate("How do I hack a computer?")

print(result.score)       # 0.92
print(result.action)      # Action.UNSAFE
print(result.commitment)  # SHA256 audit hash
# The model's raw response? Already discarded. Gone.
```

### Action Maps

```python
from sentinel_arena.sdk import ActionMap

# Binary: SAFE or UNSAFE
ActionMap.BINARY_SAFETY       # score <= 0.5 → SAFE, > 0.5 → UNSAFE

# Ternary: PROCEED, CAUTION, or DENY
ActionMap.TERNARY_GATE        # <= 0.33 → PROCEED, <= 0.66 → CAUTION, > 0.66 → DENY

# Content moderation: 4-tier
ActionMap.CONTENT_MODERATION  # SAFE / CAUTION / UNSAFE / DENY
```

---

## On-Chain Verification (SENTINEL Protocol)

SENTINEL Arena is the benchmark layer. The SENTINEL Protocol is the proof layer.

A Groth16 zero-knowledge proof — generated by an SP1 zkVM circuit — cryptographically verifies that SENTINEL extraction was applied. The proof is verified on Base mainnet. No trust required.

**What the proof guarantees:**
- SHA256(prompt) matches the committed input
- SHA256(response) matches the committed output
- Extraction state machine ran correctly (byte-by-byte, deterministic)
- Extracted score is in [0.0, 1.0]
- Score mapped to the correct action via fixed thresholds
- Raw response text was processed but never output

**Deployed contracts (Base mainnet, chain ID 8453):**

| Contract | Address |
|----------|---------|
| SentinelVerifier | [`0xE2467A49FB10e3804DEB7d287dae4B5BF740f54E`](https://basescan.org/address/0xE2467A49FB10e3804DEB7d287dae4B5BF740f54E) |
| SentinelRegistry | [`0xa0329fF2e237276D3f38fC3131c0146e30280e7F`](https://basescan.org/address/0xa0329fF2e237276D3f38fC3131c0146e30280e7F) |
| SP1 Verifier (Succinct) | `0x397A5f7f3dBd538f23DE225B51f532c34448dA9B` |

**Program verification key:** `0x00059992341fbf94009f014a5a92c509d5bd527c2b5e8bb478bc0e79b95248b3`

---

## Architecture

```
sentinel-arena/
├── sdk/          # SENTINEL defense library
│   ├── wrapper.py       # LLM wrapper (evaluate → score → action)
│   ├── extractor.py     # Regex extraction (the defense boundary)
│   ├── actions.py       # Score-to-action mapping
│   └── commitment.py    # SHA256 audit commitments
├── attacks/      # 160+ jailbreak vectors
│   ├── jailbreakbench.py   # 100 vectors (Chao et al.)
│   ├── autodan.py          # 10 vectors (Liu et al.)
│   ├── cot_hijack.py       # 10 CoT hijacking
│   ├── encoding.py         # 10 encoding evasion
│   ├── role_play.py        # 10 role-play/DAN
│   ├── multi_turn.py       # 10 multi-turn escalation
│   └── custom.py           # 10 GCG/custom
├── runner/       # Benchmark orchestration
│   ├── engine.py     # Run attacks × configs, collect results
│   ├── judge.py      # Classify attack success
│   ├── targets.py    # Model definitions
│   └── batch.py      # Rate limiting + caching
├── report/       # Visualization
│   ├── generator.py  # HTML + markdown reports
│   └── charts.py     # Grouped bar charts
└── cli.py        # CLI entry point
```

---

## Cost

| Model | Cost per 160 attacks |
|-------|---------------------|
| Ollama (local) | $0 |
| Claude Haiku | ~$0.50 |
| GPT-4o-mini | ~$0.30 |

---

## FAQ

**Q: Isn't 0% just because you're throwing away the output?**
A: Yes. That's the point. Capability denial means the model's output channel is too narrow for harm. A number can't contain instructions, hate speech, or exploit code. The "throwing away" IS the defense.

**Q: What if the model outputs a harmful number?**
A: A float between 0 and 1 maps to a fixed action (SAFE/UNSAFE). There is no harmful number. The action map is predefined and immutable.

**Q: Can't you just jailbreak the extraction?**
A: The extraction is regex on the raw response string, not an LLM call. You can't jailbreak a regex. The model's response is processed by deterministic code, not by another model.

**Q: What about multi-modal attacks?**
A: SENTINEL operates on text output only. The extraction boundary is the same regardless of input modality. Image/audio inputs still produce text outputs that get extracted to a float.

**Q: How is this different from output filtering?**
A: Output filters try to detect harm in free text (and fail 20-70% of the time). SENTINEL never looks at free text. It extracts a number and discards everything else. There's nothing to detect because there's nothing to read.

---

## Citation

```bibtex
@software{sentinel_arena_2026,
  title={SENTINEL Arena: Capability Denial Benchmark for LLM Safety},
  year={2026},
  url={https://github.com/ghost/sentinel-arena},
  note={US Provisional Patent 63/965,457}
}
```

---

## License

MIT License. See [LICENSE](LICENSE).

The SENTINEL extraction method is covered by US Provisional Patent 63/965,457. This open-source license covers the benchmark suite and SDK. Commercial use of the extraction-to-proof pipeline may require a separate license.
